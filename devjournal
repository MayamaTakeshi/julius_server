------------------------------------------------------------
2021/06/06 takeshi:

Test with wav file (containing 'ohayou gozaimasu' spoken 4 times):

$ cat /root/tmp/d.wav | ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -demo -input stdin -cutsilence
... ABRIDGED ...
Warning: strip: sample 257708-257731 has zero value, stripped
Warning: strip: sample 257930-257947 has zero value, stripped
Warning: strip: sample 259139-259154 has zero value, stripped
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.845 0.815 0.926 0.862 1.000
score1: -3815.580078 (AM: -3750.942383  LM: -64.637756)
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.801 0.814 0.927 0.839 1.000
score1: -3824.000000 (AM: -3759.362305  LM: -64.637756)
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.821 0.814 0.925 0.837 1.000
score1: -3954.950684 (AM: -3890.312988  LM: -64.637756)
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.840 0.814 0.925 0.846 1.000
score1: -3945.235107 (AM: -3880.597412  LM: -64.637756)
STAT: 0 samples (0.00 sec.)
<input rejected by short input>


Testing with raw file (endianess must be big):

$ soxi d.wav 

Input File     : 'd.wav'
Channels       : 1
Sample Rate    : 16000
Precision      : 16-bit
Duration       : 00:00:16.20 = 259200 samples ~ 1215 CDDA sectors
File Size      : 518k
Bit Rate       : 256k
Sample Encoding: 16-bit Signed Integer PCM

$ sox d.wav -t raw --endian big -e signed-integer d.raw


$ cat /root/tmp/d.raw | ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -demo -input stdin -cutsilence
... ABRIDGED ...
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.845 0.815 0.926 0.862 1.000
score1: -3815.580078 (AM: -3750.942383  LM: -64.637756)
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.801 0.814 0.927 0.839 1.000
score1: -3824.000000 (AM: -3759.362305  LM: -64.637756)
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.821 0.814 0.925 0.837 1.000
score1: -3954.950684 (AM: -3890.312988  LM: -64.637756)
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.840 0.814 0.925 0.846 1.000
score1: -3945.235107 (AM: -3880.597412  LM: -64.637756)
STAT: 0 samples (0.00 sec.)
<input rejected by short input>

------------------------------------------------------------
2021/06/06 takeshi:

Test replacing socket with STDIN worked:

$ ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -demo -input stdin -cutsilence                                                    
... ABRIDGED ...
waiting connection
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.845 0.815 0.926 0.862 1.000
score1: -3815.580078 (AM: -3750.942383  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.801 0.814 0.927 0.839 1.000
score1: -3824.000000 (AM: -3759.362305  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.821 0.814 0.925 0.837 1.000
score1: -3954.950684 (AM: -3890.312988  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.840 0.814 0.925 0.846 1.000
score1: -3945.235107 (AM: -3880.597412  LM: -64.637756)
<input rejected by short input>


Test script that caused the above output:

var net = require('net');
var fs = require('fs');
var wav = require('wav');

var HOST = '192.168.225.131';

var client1 = new net.Socket();

client1.on('error', function (e) {
  console.log("client1 ERROR: "+e.code);
});

client1.on('data', function(data) {
    console.log(`client1 data ${data}`)  
});

client1.on('close', function() {
    console.log(`client1 closed`);
});

client1.connect(10500, HOST, function() {
  console.log('client1 connected to server: ' + HOST + ':' + 10500);

  var wav_file = "/root/tmp/d.raw"

  const file = fs.createReadStream(wav_file)

  file.pipe(client1)
});


Obs: I tried using d.wav (and wav Reader) but it didn't work. I suspect it is due to difference in endianess.
But it is OK as we will not use wav in our clients.


------------------------------------------------------------
2021/06/06 takeshi:

Here is test showing data being sent to client:

$ ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -demo -input stdin -cutsilence                                                    
... ABRIDGED ...
waiting connection
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.845 0.815 0.926 0.862 1.000
score1: -3815.580078 (AM: -3750.942383  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.801 0.814 0.927 0.839 1.000
score1: -3824.000000 (AM: -3759.362305  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.821 0.814 0.925 0.837 1.000
score1: -3954.950684 (AM: -3890.312988  LM: -64.637756)
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.840 0.814 0.925 0.846 1.000
score1: -3945.235107 (AM: -3880.597412  LM: -64.637756)
<input rejected by short input>


The above output was generated by:

$ node test1.js
client1 connected to server: 192.168.225.131:10500
client1 data:
                
client1 data: おはよう
client1 data:
              
client1 data: ござい
client1 data:

client1 data: ます
client1 data:

client1 data: 。

client1 data:

client1 data: おはよう
client1 data:

client1 data: ござい
client1 data:

client1 data: ます
client1 data:

client1 data: 。
client1 data:

client1 data:

client1 data: おはよう
client1 data:

client1 data: ござい
client1 data:

client1 data: ます
client1 data:

client1 data: 。
client1 data:

client1 data:

client1 data: おはよう
client1 data:

client1 data: ござい
client1 data:

client1 data: ます
client1 data:

client1 data: 。
client1 data:

client1 closed

------------------------------------------------------------
2021/06/07 takeshi:

We will not use 
  CALLBACK_EVENT_SPEECH_READY
  CALLBACK_EVENT_SPEECH_START
  CALLBACK_EVENT_SPEECH_STOP
because these will be called each time the engine detects start/end of speech.

------------------------------------------------------------
2021/06/07 takeshi:

The test send_by_chunks.js indicate julius_server is waiting to receive all data before it process it:


$ ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -input stdin -cutsilence
waiting connections            
speech_ready   
speech_start
speech_stop                              
speech_stop
recogntion_begin
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.845 0.815 0.926 0.862 1.000
score1: -3815.580078 (AM: -3750.942383  LM: -64.637756)
recognition_end
speech_ready
speech_start
speech_stop
speech_stop
recogntion_begin
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.801 0.814 0.927 0.839 1.000
score1: -3824.000000 (AM: -3759.362305  LM: -64.637756)
recognition_end
speech_ready
speech_start
speech_stop
speech_stop
recogntion_begin
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.821 0.814 0.925 0.837 1.000
score1: -3954.950684 (AM: -3890.312988  LM: -64.637756)
recognition_end
speech_ready
speech_start
speech_stop
speech_stop
recogntion_begin
sentence1:  おはよう ござい ます 。
wseq1: <s> おはよう+感動詞 ござい+動詞 ます+助動詞 </s>
phseq1: silB | o h a y o: | g o z a i | m a s u | silE

cmscore1: 0.840 0.814 0.925 0.846 1.000
score1: -3945.235107 (AM: -3880.597412  LM: -64.637756)
recognition_end
speech_ready
speech_stop
<input rejected by short input>
recognition_end


$ node send_by_chunks.js                                                                                                                                                         
client connected to server: 192.168.225.131:10500
(node:15609) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.                    
(Use `node --trace-deprecation ...` to show where the warning was created)
Fetched 50000 bytes from audio_file.
Mon Jun 07 2021 18:39:09 GMT+0900 (Japan Standard Time) client data: +READY

Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 50000 bytes from audio_file.
Fetched 18400 bytes from audio_file.
No more data from file.
Mon Jun 07 2021 18:39:09 GMT+0900 (Japan Standard Time) client data: +SPEECH_START

Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: +RESULT:
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: おはよう
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: ござい
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: ます
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: 。
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data:

Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: +RESULT:
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: おはよう
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: ござい
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: ます
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data: 。
Mon Jun 07 2021 18:39:10 GMT+0900 (Japan Standard Time) client data:

Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data: +RESULT:
Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data: おはよう
Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data: ござい
Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data: ます
Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data: 。
Mon Jun 07 2021 18:39:11 GMT+0900 (Japan Standard Time) client data:

Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: +RESULT:
Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: おはよう
Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: ござい
Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: ます
Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: 。
Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data:

Mon Jun 07 2021 18:39:12 GMT+0900 (Japan Standard Time) client data: +END


Obs: in the above we set buffer size to 50000 but using 320 (size of RTP packet payload) just caused the transmition to take long but julius_server processed the request only after all data was received.




Maybe this is because we are replacing STDIN with a socket and using '-input stdin'. Maybe julius make different system calls and for each case.
So we will need to undo this and try force julius to read from the socket we got when forking.


------------------------------------------------------------
2021/06/07 takeshi:

Doing a test with stock julius:
[root@lab225131-basix-ban dictation-kit]$ cat /usr/local/src/git/MayamaTakeshi/julius_server/tests/artifacts/ohayou_gozaimasu.4times.wav | ./run-linux-gmm.iotbzh-julius.sh -input stdin -cutsilence 
... ABRIDGED ...
Warning: strip: sample 257708-257731 has zero value, stripped
Warning: strip: sample 257930-257947 has zero value, stripped
Warning: strip: sample 259139-259154 has zero value, stripped
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
pass1_best:  おはよう ござい ま           
sentence1:  おはよう ござい ます 。
STAT: 23800 samples (1.49 sec.)
STAT: ### speech analysis (waveform -> MFCC)
pass1_best:  おはよう ござい ま           
sentence1:  おはよう ござい ます 。
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
pass1_best:  おはよう ござい ます 。           
sentence1:  おはよう ござい ます 。
STAT: 24800 samples (1.55 sec.)
STAT: ### speech analysis (waveform -> MFCC)
pass1_best:  おはよう ござい ます 。           
sentence1:  おはよう ござい ます 。
STAT: 0 samples (0.00 sec.)
<input rejected by short input>

Error: adin_stdin: stdin reached EOF
reached end of input on stdin


It looks indeed in case of stdin, julius wants to get all the data before processing.
However, since it offers '-input mic' I assume partial recognition should be possible.

------------------------------------------------------------
2021/06/08 takeshi:

Testing with original julius with adinnet, we see something wrong:


$ node send_wav_by_chunks.js 

The above script would send ohayou gozaimasu 4 times.
But this is julius output:

[dictation-kit]$ ./run-linux-gmm.sh -input adinnet -cutsilence 
...ABRIDGED...
Warning: strip: sample 63631-63646 has zero value, stripped
pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。
pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。
STAT: no input frame

STAT: no input frame

STAT: no input frame

STAT: no input frame

STAT: no input frame

Error: rdwt: transfer data length exceeded: -1079622276 (>640000)
STAT: no input frame
Stat: adin_tcpip: connection end

Stat: adin_tcpip: waiting connection...


Notice that we only see sentence1 two times (so julius didn't get the two last ones).
It seems this hapens because of the rdwt error.


However, if we test with aditool, this problem doesn't happen:

[root@lab225131-basix-ban dictation-kit]$ bin/linux/adintool -in file -out adinnet -server 192.168.225.131
----------------------------------------                     
INPUT                                                        
           InputType: waveform                               
         InputSource: waveform file                          
        Segmentation: on, continuous                         
          SampleRate: 16000 Hz                               
               Level: 2000 / 32767                           
           ZeroCross: 60 per sec.                            
          HeadMargin: 300 msec.                              
          TailMargin: 400 msec.                              
          ZeroFrames: drop                                   
           DCRemoval: off                                    
           Auto`ause: off                                    
           LooseSync: off                                    
              Rewind: no                                     
OUTPUT                                                             
          OutputType: waveform                               
            OutputTo: adinnet server                               
              SendTo: (192.168.225.131:5530)                 
----------------------------------------                           
STAT: ###### initialize input device                         
connecting to #1 (192.168.225.131:5530)...connected                
[start recording]                                            
enter filename->/usr/local/src/git/MayamaTakeshi/julius_server/tests/artifacts/ohayou_gozaimasu.4times.wav



[root@lab225131-basix-ban dictation-kit]$ ./run-linux-gmm.sh -input adinnet -cutsilence 
... ABRIDGED ...
Stat: adin_tcpip: waiting connection...
Stat: server-client: connect from 192.168.225.131
Stat: adin_tcpip: connected
pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。

pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。

pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。

pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。

jSTAT: no input frame
Stat: adin_tcpip: connection end

Stat: adin_tcpip: waiting connection...


UPDATE:
While checking TCP audio samples transmission using tcpdump I realized it was not sending all the data in the capture (probably it was removing silence etc).
It seems the correct way to use it is:

$ bin/linux/adintool -in file -out adinnet -server 192.168.225.131 -nostrip -nosegment

which caused this output:

[root@lab225131-basix-ban dictation-kit]$ ./run-linux-gmm.iotbzh-julius.sh -input adinnet -cutsilence -nostrip
... ABRIDGED ...
Stat: adin_tcpip: waiting connection...
Stat: server-client: connect from 192.168.225.131
Stat: adin_tcpip: connected
pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。
pass1_best:  おはよう ござい ま
sentence1:  おはよう ござい ます 。
pass1_best:  おはよう ござい ます 。
sentence1:  おはよう ござい ます 。
pass1_best:  おはよう ござい ます 。
sentence1:  おはよう ござい ます 。
STAT: no input frame

STAT: no input frame
Stat: adin_tcpip: connection end

Stat: adin_tcpip: waiting connection...

which is more like the one we got using our node.js script.


UPDATE:
Solved. See: https://github.com/julius-speech/julius/issues/30#issuecomment-856461359

------------------------------------------------------------
2021/06/08 takeshi:

Explanation about how julius read sample data:
http://quruli.ivory.ne.jp/document/julius_4.2/adin__oss_8c.html#a6176085ebff799202e3fd917ce4db42d

Also in m_adin.c we see:

#ifdef ENABLE_PLUGIN
  sid = jconf->input.plugin_source;
  if (sid >= 0) {
    /* set plugin properties and functions to adin */
    func = (FUNC_INT) plugin_get_func(sid, "adin_get_configuration");
    if (func == NULL) {
      jlog("ERROR: invalid plugin: adin_get_configuration() not exist\n");
      return FALSE;
    }
    adin->silence_cut_default = (*func)(1);
    adin->enable_thread = (*func)(2);

    adin->ad_standby       = (boolean (*)(int, void *)) plugin_get_func(sid, "adin_standby");
    adin->ad_begin     = (boolean (*)(char *)) plugin_get_func(sid, "adin_open");
    adin->ad_end       = (boolean (*)()) plugin_get_func(sid, "adin_close");
    adin->ad_resume        = (boolean (*)()) plugin_get_func(sid, "adin_resume");
    adin->ad_pause     = (boolean (*)()) plugin_get_func(sid, "adin_pause");
    adin->ad_terminate     = (boolean (*)()) plugin_get_func(sid, "adin_terminate");
    adin->ad_read      = (int (*)(SP16 *, int)) plugin_get_func(sid, "adin_read");
    adin->ad_input_name    = (char * (*)()) plugin_get_func(sid, "adin_input_name");
    if (adin->ad_read == NULL) {
      jlog("ERROR: m_adin: selected plugin has no function adin_read()\n");
      return FALSE;
    }
  } else {
#endif

So we could wire a function in the plugin to do the reading.

------------------------------------------------------------
2021/06/09 takeshi:

Tests show that we cannot use '-input stdin' as we originally planned. 
The problem is that using this input mode, julius wait to fetch all data before it process it.
So we must use a real socket (adinnet or custom socket plugin).

Then the possible alternatives are:
  1) implement a plugin to permit to fetch data from the accepted socket (single fullduplex socket)
or
  2) use '-adport 0' and let the OS select a free port for the client to connect to send the audio (2 sockets one for -module and another for -adinnet)

UPDATE:
we implemented alternative 1 (fullduplex_plugin).
We start the server like this:
  ./julius_server -C ../../dictation-kit/main.jconf -C ../../dictation-kit/am-gmm.jconf -plugindir . -input fullduplex -cutsilence -nostrip


